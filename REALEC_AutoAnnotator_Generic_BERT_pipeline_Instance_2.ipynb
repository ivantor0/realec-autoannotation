{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "REALEC AutoAnnotator Generic BERT pipeline Instance 2",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "j0a4mTk9o1Qg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copyright 2019 Google Inc.\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dCpvgG0vwXAZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Predicting Movie Review Sentiment with BERT on TF Hub"
      ]
    },
    {
      "metadata": {
        "id": "xiYrZKaHwV81",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you’ve been following Natural Language Processing over the past year, you’ve probably heard of BERT: Bidirectional Encoder Representations from Transformers. It’s a neural network architecture designed by Google researchers that’s totally transformed what’s state-of-the-art for NLP tasks, like text classification, translation, summarization, and question answering.\n",
        "\n",
        "Now that BERT's been added to [TF Hub](https://www.tensorflow.org/hub) as a loadable module, it's easy(ish) to add into existing Tensorflow text pipelines. In an existing pipeline, BERT can replace text embedding layers like ELMO and GloVE. Alternatively, [finetuning](http://wiki.fast.ai/index.php/Fine_tuning) BERT can provide both an accuracy boost and faster training time in many cases.\n",
        "\n",
        "Here, we'll train a model to predict whether an IMDB movie review is positive or negative using BERT in Tensorflow with tf hub. Some code was adapted from [this colab notebook](https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb). Let's get started!"
      ]
    },
    {
      "metadata": {
        "id": "hsZvic2YxnTz",
        "colab_type": "code",
        "outputId": "8940fd81-1ce6-4fbd-a794-6651527a45d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0430 03:57:14.995656 139975260333952 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "cp5wfXDx5SPH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In addition to the standard libraries we imported above, we'll need to install BERT's python package."
      ]
    },
    {
      "metadata": {
        "id": "jviywGyWyKsA",
        "colab_type": "code",
        "outputId": "744e250a-acf6-4597-ef31-419d1eb2cb06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hhbGEfwgdEtw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PnHN2cBq-kyf",
        "colab_type": "code",
        "outputId": "4401da11-1e8f-43ef-8644-e0bd08069fc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KVB3eOcjxxm1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below, we'll set an output directory location to store our model output and checkpoints. This can be a local directory, in which case you'd set OUTPUT_DIR to the name of the directory you'd like to create. If you're running this code in Google's hosted Colab, the directory won't persist after the Colab session ends.\n",
        "\n",
        "Alternatively, if you're a GCP user, you can store output in a GCP bucket. To do that, set a directory name in OUTPUT_DIR and the name of the GCP bucket in the BUCKET field.\n",
        "\n",
        "Set DO_DELETE to rewrite the OUTPUT_DIR if it exists. Otherwise, Tensorflow will load existing model checkpoints from that directory (if they exist)."
      ]
    },
    {
      "metadata": {
        "id": "US_EAnICvP7f",
        "colab_type": "code",
        "outputId": "e0fd0d9f-3ef6-4367-9535-8ec4a95b831c",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Set the output directory for saving model file\n",
        "# Optionally, set a GCP bucket location\n",
        "\n",
        "OUTPUT_DIR = 'bert_output'#@param {type:\"string\"}\n",
        "#@markdown Whether or not to clear/delete the directory and create a new one\n",
        "DO_DELETE = False #@param {type:\"boolean\"}\n",
        "#@markdown Set USE_BUCKET and BUCKET if you want to (optionally) store model output on GCP bucket.\n",
        "USE_BUCKET = False #@param {type:\"boolean\"}\n",
        "BUCKET = 'BUCKET_NAME' #@param {type:\"string\"}\n",
        "\n",
        "if USE_BUCKET:\n",
        "  OUTPUT_DIR = 'gs://{}/{}'.format(BUCKET, OUTPUT_DIR)\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "\n",
        "if DO_DELETE:\n",
        "  try:\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "  except:\n",
        "    # Doesn't matter if the directory didn't exist\n",
        "    pass\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: bert_output *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pmFYvkylMwXn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Data"
      ]
    },
    {
      "metadata": {
        "id": "MC_w8SRqN0fr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, let's download the dataset, hosted by Stanford. The code below, which downloads, extracts, and imports the IMDB Large Movie Review Dataset, is borrowed from [this Tensorflow tutorial](https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub)."
      ]
    },
    {
      "metadata": {
        "id": "fom_ff20gyy6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QITjll8L1AnJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Conventional = [\"Generic correction\", \"Punctuation\", \"Spelling\", \"Capitalisation\", \"Grammar\", \"Determiners\", \"Articles\", \"Quantifiers\", \"Verbs\", \"Tense\", \"Choice of tense\", \"Tense form\", \"Voice\", \"Modals\", \"Verb pattern\", \"Intransitive verb\", \"Transitive verb\", \"Reflexive verb\", \"Verb with as\", \"Ambitransitive verb\", \"Two verbal forms in the predicate\", \"Verb + Infinitive\", \"Verb + Gerund\", \"Verb + Infinitive OR Gerund\", \"Verb + Bare Infinitive\", \"Verb + Object/Addressee + Bare Infinitive\", \"Infinitive Restoration Alternation\", \"Verb + Participle\", \"Get + participle\", \"Complex-object verb\", \"Verbal idiom\", \"Prepositional or phrasal verb\", \"Dative verb with alternation\", \"Verb followed by a clause\", \"Verb + that/WH + Clause\", \"Verb + if/whether + clause\", \"Verb + that + Subjunctive clause\", \"Verb + it + Conj + Clause\", \"Participial construction\", \"Infinitive construction\", \"Gerund phrase\", \"Nouns\", \"Countable/uncountable\", \"Prepositional noun\", \"Possessive form of a noun\", \"Noun as an attribute\", \"Noun + Infinitive\", \"Noun number\", \"Prepositions\", \"Conjunctions\", \"Adjectives\", \"Comparative degree of adjectives\", \"Superlative degree of adjectives\", \"Prepositional adjective\", \"Adjective as a collective noun\", \"Adverbs\", \"Comparative degree of adverbs\", \"Superlative degree of adverbs\", \"Prepositional adverb\", \"Numerals\", \"Pronouns\", \"Agreement\", \"Word order\", \"Standard word order\", \"Emphatic shift\", \"Cleft sentence\", \"Interrogative word order\", \"Incomplete sentence\", \"Exclamation\", \"Title structure\", \"Note structure\", \"Conditionals\", \"Attributes\", \"Relative clause\", \"Defining relative clause\", \"Non-defining relative clause\", \"Coordinate relative clause\", \"Attributive participial construction\", \"Parallel constructions\", \"Negation\", \"Comparative construction\", \"Numerical comparison\", \"Confusion of structures\", \"Vocabulary\", \"Word choice\", \"Choice of lexical item\", \"Words often confused\", \"Choice of a part of lexical item\", \"Absence of certain components of a collocation\", \"Redundant word(s)\", \"Word formation\", \"Derivational affixes\", \"Formational suffix\", \"Formational prefix\", \"Confusion of categories\", \"Compound word\", \"Discourse\", \"Referential device\", \"Coherence\", \"Linking device\", \"Inappropriate register\", \"Absence of a component in clause or sentence\", \"Redundant component in clause or sentence\", \"Absence of necessary explanation or detail\", \"Deletion\"]\n",
        "Tags = [\"Correction\", \"Punctuation\", \"Spelling\", \"Capitalisation\", \"Grammar\", \"Determiners\", \"Articles\", \"Quantifiers\", \"Verbs\", \"Tense\", \"Tense_choice\", \"Tense_form\", \"Voice\", \"Modals\", \"Verb_pattern\", \"Intransitive\", \"Transitive\", \"Reflexive_verb\", \"Presentation\", \"Ambitransitive\", \"Two_in_a_row\", \"Verb_Inf\", \"Verb_Gerund\", \"Verb_Inf_Gerund\", \"Verb_Bare_Inf\", \"Verb_object_bare\", \"Restoration_alter\", \"Verb_part\", \"Get_part\", \"Complex_obj\", \"Verbal_idiom\", \"Prepositional_verb\", \"Dative\", \"Followed_by_a_clause\", \"that_clause\", \"if_whether_clause\", \"that_subj_clause\", \"it_conj_clause\", \"Participial_constr\", \"Infinitive_constr\", \"Gerund_phrase\", \"Nouns\", \"Countable_uncountable\", \"Prepositional_noun\", \"Possessive\", \"Noun_attribute\", \"Noun_inf\", \"Noun_number\", \"Prepositions\", \"Conjunctions\", \"Adjectives\", \"Comparative_adj\", \"Superlative_adj\", \"Prepositional_adjective\", \"Adj_as_collective\", \"Adverbs\", \"Comparative_adv\", \"Superlative_adv\", \"Prepositional_adv\", \"Numerals\", \"Pronouns\", \"Agreement_errors\", \"Word_order\", \"Standard\", \"Emphatic\", \"Cleft\", \"Interrogative\", \"Abs_comp_clause\", \"Exclamation\", \"Title_structure\", \"Note_structure\", \"Conditionals\", \"Attributes\", \"Relative_clause\", \"Defining\", \"Non_defining\", \"Coordinate\", \"Attr_participial\", \"Lack_par_constr\", \"Negation\", \"Comparative_constr\", \"Numerical\", \"Confusion_of_structures\", \"Vocabulary\", \"Word_choice\", \"lex_item_choice\", \"Often_confused\", \"lex_part_choice\", \"Absence_comp_colloc\", \"Redundant\", \"Derivation\", \"Formational_affixes\", \"Suffix\", \"Prefix\", \"Category_confusion\", \"Compound_word\", \"Discourse\", \"Ref_device\", \"Coherence\", \"Linking_device\", \"Inappropriate_register\", \"Absence_comp_sent\", \"Redundant_comp\", \"Absence_explanation\", \"delete\"]\n",
        "translate_dict = {e[0]: e[1] for e in zip(Conventional, Tags)}\n",
        "\n",
        "error_type = \"Choice of lexical item\" #@param [\"Spelling\", \"Choice of lexical item\", \"Deletion\", \"Prepositions\", \"Agreement\", \"Noun number\", \"Confusion of categories\", \"Referential device\", \"Capitalisation\", \"Words often confused\"]\n",
        "error_ratio = \"AugmentedRatio\" #@param [\"ToFifteen\", \"AugmentedRatio\"]\n",
        "\n",
        "error_type = translate_dict[error_type]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DHdoFRKc4cqQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It's about time we named our model"
      ]
    },
    {
      "metadata": {
        "id": "OBrzdw7j4eer",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelname = \"lex_item_choice_AugmentedRatio\" # @param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AkQn6bJK_CIB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "filename = error_ratio+\"/train/\"+error_type+\".json\"\n",
        "shutil.copy2('/content/gdrive/My Drive/Datasets/'+filename,'.')\n",
        "trn = pd.read_json(error_type+\".json\").reset_index(drop=True)\n",
        "trn[\"is_error\"] = trn[\"is_error\"].astype(int)\n",
        "\n",
        "filename = error_ratio+\"/test/\"+error_type+\".json\"\n",
        "shutil.copy2('/content/gdrive/My Drive/Datasets/'+filename,'./'+error_type+'_test.json')\n",
        "tst = pd.read_json(error_type+\"_test.json\").reset_index(drop=True)\n",
        "tst[\"is_error\"] = tst[\"is_error\"].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wBe3GK5Rhja7",
        "colab_type": "code",
        "outputId": "4044934a-db80-433d-ff53-7ee6f3dc1ae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(trn)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "113830"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "XA8WHJgzhIZf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To keep training fast, we'll take a sample of 5000 train and test examples, respectively."
      ]
    },
    {
      "metadata": {
        "id": "Hqutj52z7yVP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = trn\n",
        "test = tst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "prRQM8pDi8xI",
        "colab_type": "code",
        "outputId": "3cd18af4-2210-468c-e3a1-1358628421ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train.columns"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['context', 'is_error', 'path', 'substring'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "sfRnHSz3iSXz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For us, our input data is the 'sentence' column and our label is the 'polarity' column (0, 1 for negative and positive, respecitvely)"
      ]
    },
    {
      "metadata": {
        "id": "IuMOGwFui4it",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATA_COLUMN = 'context'\n",
        "SUBSTR_COLUMN = 'substring'\n",
        "LABEL_COLUMN = 'is_error'\n",
        "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
        "label_list = [0, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V399W0rqNJ-Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing\n",
        "We'll need to transform our data into a format BERT understands. This involves two steps. First, we create  `InputExample`'s using the constructor provided in the BERT library.\n",
        "\n",
        "- `text_a` is the text we want to classify, which in this case, is the `Request` field in our Dataframe. \n",
        "- `text_b` is used if we're training a model to understand the relationship between sentences (i.e. is `text_b` a translation of `text_a`? Is `text_b` an answer to the question asked by `text_a`?). This doesn't apply to our task, so we can leave `text_b` blank.\n",
        "- `label` is the label for our example, i.e. True, False"
      ]
    },
    {
      "metadata": {
        "id": "p9gEt5SmM6i6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = x[SUBSTR_COLUMN], \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = x[SUBSTR_COLUMN], \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H7fHpWRZYZpp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1156
        },
        "outputId": "6fbba759-ca5c-4c7a-94ad-2f0f327db16f"
      },
      "cell_type": "code",
      "source": [
        "train_InputExamples"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         <bert.run_classifier.InputExample object at 0x...\n",
              "1         <bert.run_classifier.InputExample object at 0x...\n",
              "2         <bert.run_classifier.InputExample object at 0x...\n",
              "3         <bert.run_classifier.InputExample object at 0x...\n",
              "4         <bert.run_classifier.InputExample object at 0x...\n",
              "5         <bert.run_classifier.InputExample object at 0x...\n",
              "6         <bert.run_classifier.InputExample object at 0x...\n",
              "7         <bert.run_classifier.InputExample object at 0x...\n",
              "8         <bert.run_classifier.InputExample object at 0x...\n",
              "9         <bert.run_classifier.InputExample object at 0x...\n",
              "10        <bert.run_classifier.InputExample object at 0x...\n",
              "11        <bert.run_classifier.InputExample object at 0x...\n",
              "12        <bert.run_classifier.InputExample object at 0x...\n",
              "13        <bert.run_classifier.InputExample object at 0x...\n",
              "14        <bert.run_classifier.InputExample object at 0x...\n",
              "15        <bert.run_classifier.InputExample object at 0x...\n",
              "16        <bert.run_classifier.InputExample object at 0x...\n",
              "17        <bert.run_classifier.InputExample object at 0x...\n",
              "18        <bert.run_classifier.InputExample object at 0x...\n",
              "19        <bert.run_classifier.InputExample object at 0x...\n",
              "20        <bert.run_classifier.InputExample object at 0x...\n",
              "21        <bert.run_classifier.InputExample object at 0x...\n",
              "22        <bert.run_classifier.InputExample object at 0x...\n",
              "23        <bert.run_classifier.InputExample object at 0x...\n",
              "24        <bert.run_classifier.InputExample object at 0x...\n",
              "25        <bert.run_classifier.InputExample object at 0x...\n",
              "26        <bert.run_classifier.InputExample object at 0x...\n",
              "27        <bert.run_classifier.InputExample object at 0x...\n",
              "28        <bert.run_classifier.InputExample object at 0x...\n",
              "29        <bert.run_classifier.InputExample object at 0x...\n",
              "                                ...                        \n",
              "113800    <bert.run_classifier.InputExample object at 0x...\n",
              "113801    <bert.run_classifier.InputExample object at 0x...\n",
              "113802    <bert.run_classifier.InputExample object at 0x...\n",
              "113803    <bert.run_classifier.InputExample object at 0x...\n",
              "113804    <bert.run_classifier.InputExample object at 0x...\n",
              "113805    <bert.run_classifier.InputExample object at 0x...\n",
              "113806    <bert.run_classifier.InputExample object at 0x...\n",
              "113807    <bert.run_classifier.InputExample object at 0x...\n",
              "113808    <bert.run_classifier.InputExample object at 0x...\n",
              "113809    <bert.run_classifier.InputExample object at 0x...\n",
              "113810    <bert.run_classifier.InputExample object at 0x...\n",
              "113811    <bert.run_classifier.InputExample object at 0x...\n",
              "113812    <bert.run_classifier.InputExample object at 0x...\n",
              "113813    <bert.run_classifier.InputExample object at 0x...\n",
              "113814    <bert.run_classifier.InputExample object at 0x...\n",
              "113815    <bert.run_classifier.InputExample object at 0x...\n",
              "113816    <bert.run_classifier.InputExample object at 0x...\n",
              "113817    <bert.run_classifier.InputExample object at 0x...\n",
              "113818    <bert.run_classifier.InputExample object at 0x...\n",
              "113819    <bert.run_classifier.InputExample object at 0x...\n",
              "113820    <bert.run_classifier.InputExample object at 0x...\n",
              "113821    <bert.run_classifier.InputExample object at 0x...\n",
              "113822    <bert.run_classifier.InputExample object at 0x...\n",
              "113823    <bert.run_classifier.InputExample object at 0x...\n",
              "113824    <bert.run_classifier.InputExample object at 0x...\n",
              "113825    <bert.run_classifier.InputExample object at 0x...\n",
              "113826    <bert.run_classifier.InputExample object at 0x...\n",
              "113827    <bert.run_classifier.InputExample object at 0x...\n",
              "113828    <bert.run_classifier.InputExample object at 0x...\n",
              "113829    <bert.run_classifier.InputExample object at 0x...\n",
              "Length: 113830, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "SCZWZtKxObjh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we need to preprocess our data so that it matches the data BERT was trained on. For this, we'll need to do a couple of things (but don't worry--this is also included in the Python library):\n",
        "\n",
        "\n",
        "1. Lowercase our text (if we're using a BERT lowercase model)\n",
        "2. Tokenize it (i.e. \"sally says hi\" -> [\"sally\", \"says\", \"hi\"])\n",
        "3. Break words into WordPieces (i.e. \"calling\" -> [\"call\", \"##ing\"])\n",
        "4. Map our words to indexes using a vocab file that BERT provides\n",
        "5. Add special \"CLS\" and \"SEP\" tokens (see the [readme](https://github.com/google-research/bert))\n",
        "6. Append \"index\" and \"segment\" tokens to each input (see the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf))\n",
        "\n",
        "Happily, we don't have to worry about most of these details.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "qMWiDtpyQSoU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To start, we'll need to load a vocabulary file and lowercasing information directly from the BERT tf hub module:"
      ]
    },
    {
      "metadata": {
        "id": "IhJSe0QHNG7U",
        "colab_type": "code",
        "outputId": "03814c09-4cd1-4eea-8e14-e101ccd96920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "cell_type": "code",
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_cased_L-12_H-768_A-12/1\"\n",
        "\n",
        "class NonMaskOmittingTokenizer(bert.tokenization.FullTokenizer):\n",
        "  def tokenize(self, text):\n",
        "    split_tokens = []\n",
        "    for token in self.basic_tokenizer.tokenize(text):\n",
        "      for sub_token in self.wordpiece_tokenizer.tokenize(token):\n",
        "        split_tokens.append(sub_token)\n",
        "\n",
        "    for index, item in enumerate(split_tokens):\n",
        "      if index >= len(split_tokens)-2:\n",
        "        break\n",
        "      if item == '[' and split_tokens[index + 1] == 'MA' and split_tokens[index + 2] == '##S' and split_tokens[index + 3] == '##K' and split_tokens[index + 4] == ']':\n",
        "        split_tokens[index] = \"[MASK]\"\n",
        "        del split_tokens[index + 1]\n",
        "        del split_tokens[index + 1]\n",
        "        del split_tokens[index + 1]\n",
        "        del split_tokens[index + 1]\n",
        "\n",
        "    return split_tokens\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return NonMaskOmittingTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0430 03:57:31.199304 139975260333952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:33.152627 139975260333952 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "z4oFkhpZBDKm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Great--we just learned that the BERT model we're using expects lowercase data (that's what stored in tokenization_info[\"do_lower_case\"]) and we also loaded BERT's vocab file. We also created a tokenizer, which breaks words into word pieces:"
      ]
    },
    {
      "metadata": {
        "id": "dsBo6RCtQmwx",
        "colab_type": "code",
        "outputId": "fee19669-f503-446b-ffd5-a03e2f19533e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(\"This here's an example of using the BERT [MASK] tokenizer\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'here',\n",
              " \"'\",\n",
              " 's',\n",
              " 'an',\n",
              " 'example',\n",
              " 'of',\n",
              " 'using',\n",
              " 'the',\n",
              " 'B',\n",
              " '##ER',\n",
              " '##T',\n",
              " '[MASK]',\n",
              " 'token',\n",
              " '##izer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "0OEzfFIt6GIc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using our tokenizer, we'll call `run_classifier.convert_examples_to_features` on our InputExamples to convert them into features BERT understands."
      ]
    },
    {
      "metadata": {
        "id": "LL5W8gEGRTAf",
        "colab_type": "code",
        "outputId": "a4373d00-3f0d-4b4b-b00a-5f1e1f9e15d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3159
        }
      },
      "cell_type": "code",
      "source": [
        "# We'll set sequences to be at most 128 tokens long.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "# Convert our train and test features to InputFeatures that BERT understands.\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 113830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.271622 139975260333952 run_classifier.py:774] Writing example 0 of 113830\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.275420 139975260333952 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.277766 139975260333952 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] For example , in this year O ##lim ##pic Games encouraged people . People [MASK] to do sport more . That ` s why , it influenced on public health positively . [SEP] became [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.279939 139975260333952 run_classifier.py:464] tokens: [CLS] For example , in this year O ##lim ##pic Games encouraged people . People [MASK] to do sport more . That ` s why , it influenced on public health positively . [SEP] became [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1370 1859 117 1107 1142 1214 152 24891 20437 2957 6182 1234 119 2563 103 1106 1202 4799 1167 119 1337 169 188 1725 117 1122 4401 1113 1470 2332 14257 119 102 1245 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.283495 139975260333952 run_classifier.py:465] input_ids: 101 1370 1859 117 1107 1142 1214 152 24891 20437 2957 6182 1234 119 2563 103 1106 1202 4799 1167 119 1337 169 188 1725 117 1122 4401 1113 1470 2332 14257 119 102 1245 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.287259 139975260333952 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.291137 139975260333952 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.294957 139975260333952 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.299318 139975260333952 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.301794 139975260333952 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] The information given illustrate ##s the amount of investment in renewable energy given by two types of countries such as developed and developing countries from 2006 to 2013 , and it also shows , in comparison , the amount of investment as a world total over [MASK] period . It can be de ##duced from the graph that investments that were done in developed countries remained considerably higher than investments in developing countries from 2006 to 2013 . [SEP] similar [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.303758 139975260333952 run_classifier.py:464] tokens: [CLS] The information given illustrate ##s the amount of investment in renewable energy given by two types of countries such as developed and developing countries from 2006 to 2013 , and it also shows , in comparison , the amount of investment as a world total over [MASK] period . It can be de ##duced from the graph that investments that were done in developed countries remained considerably higher than investments in developing countries from 2006 to 2013 . [SEP] similar [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1109 1869 1549 20873 1116 1103 2971 1104 5151 1107 17216 2308 1549 1118 1160 3322 1104 2182 1216 1112 1872 1105 4297 2182 1121 1386 1106 1381 117 1105 1122 1145 2196 117 1107 7577 117 1103 2971 1104 5151 1112 170 1362 1703 1166 103 1669 119 1135 1169 1129 1260 20196 1121 1103 10873 1115 12372 1115 1127 1694 1107 1872 2182 1915 9627 2299 1190 12372 1107 4297 2182 1121 1386 1106 1381 119 102 1861 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.305905 139975260333952 run_classifier.py:465] input_ids: 101 1109 1869 1549 20873 1116 1103 2971 1104 5151 1107 17216 2308 1549 1118 1160 3322 1104 2182 1216 1112 1872 1105 4297 2182 1121 1386 1106 1381 117 1105 1122 1145 2196 117 1107 7577 117 1103 2971 1104 5151 1112 170 1362 1703 1166 103 1669 119 1135 1169 1129 1260 20196 1121 1103 10873 1115 12372 1115 1127 1694 1107 1872 2182 1915 9627 2299 1190 12372 1107 4297 2182 1121 1386 1106 1381 119 102 1861 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.307791 139975260333952 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.309682 139975260333952 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.311536 139975260333952 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.315669 139975260333952 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.317707 139975260333952 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] The point where percentage in two countries matches concerns people with the income slightly higher than that accepted middle . In both countries people of this [MASK] spend approximately 4 per cent of their income on petrol . On the whole , the overall tendencies are significantly different in two countries but the most remarkable difference lies in the class of poor ##est people whereas the richest people behave similarly in the UK and in the USA . [SEP] class [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.319798 139975260333952 run_classifier.py:464] tokens: [CLS] The point where percentage in two countries matches concerns people with the income slightly higher than that accepted middle . In both countries people of this [MASK] spend approximately 4 per cent of their income on petrol . On the whole , the overall tendencies are significantly different in two countries but the most remarkable difference lies in the class of poor ##est people whereas the richest people behave similarly in the UK and in the USA . [SEP] class [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1109 1553 1187 6556 1107 1160 2182 2697 5365 1234 1114 1103 2467 2776 2299 1190 1115 3134 2243 119 1130 1241 2182 1234 1104 1142 103 4511 2324 125 1679 9848 1104 1147 2467 1113 19847 119 1212 1103 2006 117 1103 2905 23581 1132 5409 1472 1107 1160 2182 1133 1103 1211 9495 3719 2887 1107 1103 1705 1104 2869 2556 1234 6142 1103 20513 1234 18492 9279 1107 1103 1993 1105 1107 1103 3066 119 102 1705 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.321705 139975260333952 run_classifier.py:465] input_ids: 101 1109 1553 1187 6556 1107 1160 2182 2697 5365 1234 1114 1103 2467 2776 2299 1190 1115 3134 2243 119 1130 1241 2182 1234 1104 1142 103 4511 2324 125 1679 9848 1104 1147 2467 1113 19847 119 1212 1103 2006 117 1103 2905 23581 1132 5409 1472 1107 1160 2182 1133 1103 1211 9495 3719 2887 1107 1103 1705 1104 2869 2556 1234 6142 1103 20513 1234 18492 9279 1107 1103 1993 1105 1107 1103 3066 119 102 1705 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.323850 139975260333952 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.325722 139975260333952 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.327660 139975260333952 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.331215 139975260333952 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.333156 139975260333952 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] The trends of g ##rat ##h ’ s development for Sweden and USA are nearly the same . The key difference is that USA ’ s t ##rand is having a stable period during 2000 - s - 2020 - s while Sweden has [MASK] rise and then slight fall in population age ##n 65 . This situation have caused difference in latest per ##sent ##s at 204 ##0s . [SEP] rapid [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.335264 139975260333952 run_classifier.py:464] tokens: [CLS] The trends of g ##rat ##h ’ s development for Sweden and USA are nearly the same . The key difference is that USA ’ s t ##rand is having a stable period during 2000 - s - 2020 - s while Sweden has [MASK] rise and then slight fall in population age ##n 65 . This situation have caused difference in latest per ##sent ##s at 204 ##0s . [SEP] rapid [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1109 14652 1104 176 7625 1324 787 188 1718 1111 3865 1105 3066 1132 2212 1103 1269 119 1109 2501 3719 1110 1115 3066 787 188 189 13141 1110 1515 170 6111 1669 1219 1539 118 188 118 12795 118 188 1229 3865 1144 103 3606 1105 1173 6812 2303 1107 1416 1425 1179 2625 119 1188 2820 1138 2416 3719 1107 6270 1679 27408 1116 1120 21355 13031 119 102 6099 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.337300 139975260333952 run_classifier.py:465] input_ids: 101 1109 14652 1104 176 7625 1324 787 188 1718 1111 3865 1105 3066 1132 2212 1103 1269 119 1109 2501 3719 1110 1115 3066 787 188 189 13141 1110 1515 170 6111 1669 1219 1539 118 188 118 12795 118 188 1229 3865 1144 103 3606 1105 1173 6812 2303 1107 1416 1425 1179 2625 119 1188 2820 1138 2416 3719 1107 6270 1679 27408 1116 1120 21355 13031 119 102 6099 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.339280 139975260333952 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.341343 139975260333952 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.343247 139975260333952 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.347159 139975260333952 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.352445 139975260333952 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] Modern world has really big problem , on the one hand , with health of human ##ices , but at the same time , has active develop of technology which try to reduce our problems q ##ui ##c ##ly . Clearly , that nowadays [MASK] can ’ t imagine our life without modern technology . So , some people have big problem with health , because they don ’ t know how to right connected with technology . [SEP] human [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.354389 139975260333952 run_classifier.py:464] tokens: [CLS] Modern world has really big problem , on the one hand , with health of human ##ices , but at the same time , has active develop of technology which try to reduce our problems q ##ui ##c ##ly . Clearly , that nowadays [MASK] can ’ t imagine our life without modern technology . So , some people have big problem with health , because they don ’ t know how to right connected with technology . [SEP] human [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4825 1362 1144 1541 1992 2463 117 1113 1103 1141 1289 117 1114 2332 1104 1769 18117 117 1133 1120 1103 1269 1159 117 1144 2327 3689 1104 2815 1134 2222 1106 4851 1412 2645 186 6592 1665 1193 119 19260 117 1115 20148 103 1169 787 189 5403 1412 1297 1443 2030 2815 119 1573 117 1199 1234 1138 1992 2463 1114 2332 117 1272 1152 1274 787 189 1221 1293 1106 1268 3387 1114 2815 119 102 1769 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.356398 139975260333952 run_classifier.py:465] input_ids: 101 4825 1362 1144 1541 1992 2463 117 1113 1103 1141 1289 117 1114 2332 1104 1769 18117 117 1133 1120 1103 1269 1159 117 1144 2327 3689 1104 2815 1134 2222 1106 4851 1412 2645 186 6592 1665 1193 119 19260 117 1115 20148 103 1169 787 189 5403 1412 1297 1443 2030 2815 119 1573 117 1199 1234 1138 1992 2463 1114 2332 117 1272 1152 1274 787 189 1221 1293 1106 1268 3387 1114 2815 119 102 1769 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.358580 139975260333952 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.361145 139975260333952 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:34.363121 139975260333952 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 113830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:46.432544 139975260333952 run_classifier.py:774] Writing example 10000 of 113830\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 113830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:57:58.421946 139975260333952 run_classifier.py:774] Writing example 20000 of 113830\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 30000 of 113830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:58:10.128169 139975260333952 run_classifier.py:774] Writing example 30000 of 113830\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 40000 of 113830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:58:21.904155 139975260333952 run_classifier.py:774] Writing example 40000 of 113830\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 50000 of 113830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:58:34.157414 139975260333952 run_classifier.py:774] Writing example 50000 of 113830\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 60000 of 113830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:58:46.652529 139975260333952 run_classifier.py:774] Writing example 60000 of 113830\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 70000 of 113830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:58:58.867246 139975260333952 run_classifier.py:774] Writing example 70000 of 113830\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 80000 of 113830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:10.959184 139975260333952 run_classifier.py:774] Writing example 80000 of 113830\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 90000 of 113830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:22.603003 139975260333952 run_classifier.py:774] Writing example 90000 of 113830\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 100000 of 113830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:34.326308 139975260333952 run_classifier.py:774] Writing example 100000 of 113830\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 110000 of 113830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:46.644879 139975260333952 run_classifier.py:774] Writing example 110000 of 113830\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 28458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.116697 139975260333952 run_classifier.py:774] Writing example 0 of 28458\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.119968 139975260333952 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.123645 139975260333952 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] The first diagram gives information about products , which is delivered by rail . It is noticeable that the [MASK] feature of the first graph is percentage of transported metals ( 35 % ) . In contrast , road transportation has only 11 % of metals delivery , but it provides 28 % of manufactured goods transportation . [SEP] mean [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.127698 139975260333952 run_classifier.py:464] tokens: [CLS] The first diagram gives information about products , which is delivered by rail . It is noticeable that the [MASK] feature of the first graph is percentage of transported metals ( 35 % ) . In contrast , road transportation has only 11 % of metals delivery , but it provides 28 % of manufactured goods transportation . [SEP] mean [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1109 1148 18217 3114 1869 1164 2982 117 1134 1110 4653 1118 4356 119 1135 1110 19178 1115 1103 103 2672 1104 1103 1148 10873 1110 6556 1104 9470 13237 113 2588 110 114 119 1130 5014 117 1812 6312 1144 1178 1429 110 1104 13237 6779 117 1133 1122 2790 1743 110 1104 7227 4817 6312 119 102 1928 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.130799 139975260333952 run_classifier.py:465] input_ids: 101 1109 1148 18217 3114 1869 1164 2982 117 1134 1110 4653 1118 4356 119 1135 1110 19178 1115 1103 103 2672 1104 1103 1148 10873 1110 6556 1104 9470 13237 113 2588 110 114 119 1130 5014 117 1812 6312 1144 1178 1429 110 1104 13237 6779 117 1133 1122 2790 1743 110 1104 7227 4817 6312 119 102 1928 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.134088 139975260333952 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.137130 139975260333952 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.140374 139975260333952 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.145451 139975260333952 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.147094 139975260333952 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] And the best punishment for a sports ##man is a banning from all the competitions for the rest of his / her life . On the other hand , everyone should have a chance to make himself better , to recognize mistakes and do all his best to [MASK] it . If there is an opportunity that if a sports ##man was banned , he would not repeat such actions anymore . [SEP] improve [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.149575 139975260333952 run_classifier.py:464] tokens: [CLS] And the best punishment for a sports ##man is a banning from all the competitions for the rest of his / her life . On the other hand , everyone should have a chance to make himself better , to recognize mistakes and do all his best to [MASK] it . If there is an opportunity that if a sports ##man was banned , he would not repeat such actions anymore . [SEP] improve [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1262 1103 1436 7703 1111 170 2865 1399 1110 170 26380 1121 1155 1103 6025 1111 1103 1832 1104 1117 120 1123 1297 119 1212 1103 1168 1289 117 2490 1431 1138 170 2640 1106 1294 1471 1618 117 1106 6239 12572 1105 1202 1155 1117 1436 1106 103 1122 119 1409 1175 1110 1126 3767 1115 1191 170 2865 1399 1108 7548 117 1119 1156 1136 9488 1216 3721 4169 119 102 4607 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.152549 139975260333952 run_classifier.py:465] input_ids: 101 1262 1103 1436 7703 1111 170 2865 1399 1110 170 26380 1121 1155 1103 6025 1111 1103 1832 1104 1117 120 1123 1297 119 1212 1103 1168 1289 117 2490 1431 1138 170 2640 1106 1294 1471 1618 117 1106 6239 12572 1105 1202 1155 1117 1436 1106 103 1122 119 1409 1175 1110 1126 3767 1115 1191 170 2865 1399 1108 7548 117 1119 1156 1136 9488 1216 3721 4169 119 102 4607 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.156088 139975260333952 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.159276 139975260333952 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.161433 139975260333952 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.166517 139975260333952 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.170177 139975260333952 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] l ##hat the offered policy is not appropriate . There is no doubt that if we admit the requirement of equal number of students of both gender ##s we will also agree with the fact that intellectual or mental abilities of male and female [MASK] . Of course , centuries ago men and women didn ’ t have similar rights and opportunities . [SEP] differentiate [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.173421 139975260333952 run_classifier.py:464] tokens: [CLS] l ##hat the offered policy is not appropriate . There is no doubt that if we admit the requirement of equal number of students of both gender ##s we will also agree with the fact that intellectual or mental abilities of male and female [MASK] . Of course , centuries ago men and women didn ’ t have similar rights and opportunities . [SEP] differentiate [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 181 11220 1103 2356 2818 1110 1136 5806 119 1247 1110 1185 4095 1115 1191 1195 5890 1103 8875 1104 4463 1295 1104 1651 1104 1241 5772 1116 1195 1209 1145 5340 1114 1103 1864 1115 8066 1137 4910 7134 1104 2581 1105 2130 103 119 2096 1736 117 3944 2403 1441 1105 1535 1238 787 189 1138 1861 2266 1105 6305 119 102 23159 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.176482 139975260333952 run_classifier.py:465] input_ids: 101 181 11220 1103 2356 2818 1110 1136 5806 119 1247 1110 1185 4095 1115 1191 1195 5890 1103 8875 1104 4463 1295 1104 1651 1104 1241 5772 1116 1195 1209 1145 5340 1114 1103 1864 1115 8066 1137 4910 7134 1104 2581 1105 2130 103 119 2096 1736 117 3944 2403 1441 1105 1535 1238 787 189 1138 1861 2266 1105 6305 119 102 23159 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.180329 139975260333952 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.182551 139975260333952 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.185519 139975260333952 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.191949 139975260333952 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.194108 139975260333952 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] In spite of this , money is believed to be significant no less than happiness . The main argument in favor of money is people say that you won ’ t be happy before you earn a big n [MASK] of money . From this point of view , in our world it is money that di ##ct ##ates us the rules . [SEP] number [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.196407 139975260333952 run_classifier.py:464] tokens: [CLS] In spite of this , money is believed to be significant no less than happiness . The main argument in favor of money is people say that you won ’ t be happy before you earn a big n [MASK] of money . From this point of view , in our world it is money that di ##ct ##ates us the rules . [SEP] number [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1130 8438 1104 1142 117 1948 1110 2475 1106 1129 2418 1185 1750 1190 9266 119 1109 1514 6171 1107 5010 1104 1948 1110 1234 1474 1115 1128 1281 787 189 1129 2816 1196 1128 7379 170 1992 183 103 1104 1948 119 1622 1142 1553 1104 2458 117 1107 1412 1362 1122 1110 1948 1115 4267 5822 5430 1366 1103 2995 119 102 1295 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.198855 139975260333952 run_classifier.py:465] input_ids: 101 1130 8438 1104 1142 117 1948 1110 2475 1106 1129 2418 1185 1750 1190 9266 119 1109 1514 6171 1107 5010 1104 1948 1110 1234 1474 1115 1128 1281 787 189 1129 2816 1196 1128 7379 170 1992 183 103 1104 1948 119 1622 1142 1553 1104 2458 117 1107 1412 1362 1122 1110 1948 1115 4267 5822 5430 1366 1103 2995 119 102 1295 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.204210 139975260333952 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.209675 139975260333952 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.214670 139975260333952 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.220377 139975260333952 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.224729 139975260333952 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] After this increase we can see steady fall from 206 ##0 to 210 ##0 . In fact the lowest level of extinction of species was [MASK] in 2000 , it was about 5000 dying out per million species . A more detailed look at the chart reveals that human impact makes up 81 , 3 per cent , that makes it the main threat to plant life . [SEP] fixed [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.228221 139975260333952 run_classifier.py:464] tokens: [CLS] After this increase we can see steady fall from 206 ##0 to 210 ##0 . In fact the lowest level of extinction of species was [MASK] in 2000 , it was about 5000 dying out per million species . A more detailed look at the chart reveals that human impact makes up 81 , 3 per cent , that makes it the main threat to plant life . [SEP] fixed [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1258 1142 2773 1195 1169 1267 6386 2303 1121 20278 1568 1106 13075 1568 119 1130 1864 1103 6905 1634 1104 16137 1104 1530 1108 103 1107 1539 117 1122 1108 1164 13837 5694 1149 1679 1550 1530 119 138 1167 6448 1440 1120 1103 3481 7189 1115 1769 3772 2228 1146 5615 117 124 1679 9848 117 1115 2228 1122 1103 1514 4433 1106 2582 1297 119 102 4275 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.230962 139975260333952 run_classifier.py:465] input_ids: 101 1258 1142 2773 1195 1169 1267 6386 2303 1121 20278 1568 1106 13075 1568 119 1130 1864 1103 6905 1634 1104 16137 1104 1530 1108 103 1107 1539 117 1122 1108 1164 13837 5694 1149 1679 1550 1530 119 138 1167 6448 1440 1120 1103 3481 7189 1115 1769 3772 2228 1146 5615 117 124 1679 9848 117 1115 2228 1122 1103 1514 4433 1106 2582 1297 119 102 4275 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.233501 139975260333952 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.237563 139975260333952 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 03:59:51.241966 139975260333952 run_classifier.py:468] label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 28458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 04:00:04.253672 139975260333952 run_classifier.py:774] Writing example 10000 of 28458\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 28458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 04:00:15.894225 139975260333952 run_classifier.py:774] Writing example 20000 of 28458\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ccp5trMwRtmr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Creating a model\n",
        "\n",
        "Now that we've prepared our data, let's focus on building a model. `create_model` does just this below. First, it loads the BERT tf hub module again (this time to extract the computation graph). Next, it creates a single new layer that will be trained to adapt BERT to our sentiment task (i.e. classifying whether a movie review is positive or negative). This strategy of using a mostly trained model is called [fine-tuning](http://wiki.fast.ai/index.php/Fine_tuning)."
      ]
    },
    {
      "metadata": {
        "id": "6o2a5ZIvRcJq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "  bert_module = hub.Module(\n",
        "      BERT_MODEL_HUB,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qpE0ZIDOCQzE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next we'll wrap our model function in a `model_fn_builder` function that adapts our model to work for training, evaluation, and prediction."
      ]
    },
    {
      "metadata": {
        "id": "FnH-AnOQ9KKW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        f1_score = tf.contrib.metrics.f1_score(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        auc = tf.metrics.auc(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predicted_labels) \n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"f1_score\": f1_score,\n",
        "            \"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OjwJ4bTeWXD8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 3.0\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 500\n",
        "SAVE_SUMMARY_STEPS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "emHf9GhfWBZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "70b58133-f3fa-4185-eb19-098b708bb203"
      },
      "cell_type": "code",
      "source": [
        "# Compute # train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS) * 2\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "print(num_train_steps)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oEJldMr3WYZa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specify outpit directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q_WebpS1X97v",
        "colab_type": "code",
        "outputId": "389bf349-9c1a-40ec-e342-e0f853f9774a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "cell_type": "code",
      "source": [
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'bert_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4e12a12cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 04:00:27.310226 139975260333952 estimator.py:201] Using config: {'_model_dir': 'bert_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4e12a12cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NOO3RfG1DYLo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next we create an input builder function that takes our training feature set (`train_features`) and produces a generator. This is a pretty standard design pattern for working with Tensorflow [Estimators](https://www.tensorflow.org/guide/estimators)."
      ]
    },
    {
      "metadata": {
        "id": "1Pv2bAlOX_-K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nucD4gluYJmK",
        "colab_type": "code",
        "outputId": "c65caf34-3810-4290-b43e-8007a424dbf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "cell_type": "code",
      "source": [
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 04:05:18.021401 139975260333952 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 04:05:22.001494 139975260333952 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 04:05:32.652002 139975260333952 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 04:05:32.656268 139975260333952 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 04:05:34.347628 139975260333952 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from bert_output/model.ckpt-1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 04:05:34.362075 139975260333952 saver.py:1270] Restoring parameters from bert_output/model.ckpt-1000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 04:05:40.166129 139975260333952 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0430 04:05:40.418961 139975260333952 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "t6Nukby2EB6-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we train our model! For me, using a Colab notebook running on Google's GPUs, my training time was about 14 minutes."
      ]
    },
    {
      "metadata": {
        "id": "CmbLTVniARy3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's use our test data to see how well our model did:"
      ]
    },
    {
      "metadata": {
        "id": "JIhejfpyJ8Bx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_input_fn = run_classifier.input_fn_builder(\n",
        "    features=test_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PPVEXhNjYXC-",
        "colab_type": "code",
        "outputId": "42dde0bd-1a75-4779-d071-219982498fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        }
      },
      "cell_type": "code",
      "source": [
        "estimator.evaluate(input_fn=test_input_fn, steps=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-02-20T22:24:15Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from OUTPUT_DIR_NAME/model.ckpt-1874\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-02-20-22:27:05\n",
            "INFO:tensorflow:Saving dict for global step 1874: auc = 0.59808373, eval_accuracy = 0.931, f1_score = 0.27368414, false_negatives = 459.0, false_positives = 231.0, global_step = 1874, loss = 0.39963886, precision = 0.3601108, recall = 0.22071308, true_negatives = 9180.0, true_positives = 130.0\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1874: OUTPUT_DIR_NAME/model.ckpt-1874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc': 0.59808373,\n",
              " 'eval_accuracy': 0.931,\n",
              " 'f1_score': 0.27368414,\n",
              " 'false_negatives': 459.0,\n",
              " 'false_positives': 231.0,\n",
              " 'global_step': 1874,\n",
              " 'loss': 0.39963886,\n",
              " 'precision': 0.3601108,\n",
              " 'recall': 0.22071308,\n",
              " 'true_negatives': 9180.0,\n",
              " 'true_positives': 130.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "uettEz32yqIN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Extracting the trained model\n"
      ]
    },
    {
      "metadata": {
        "id": "ueKsULteiz1B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's save our model:"
      ]
    },
    {
      "metadata": {
        "id": "CjLrbBFG4GMx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Export the model\n",
        "def serving_input_fn():\n",
        "  with tf.variable_scope(\"foo\"):\n",
        "    feature_spec = {\n",
        "        \"input_ids\": tf.FixedLenFeature([MAX_SEQ_LENGTH], tf.int64),\n",
        "        \"input_mask\": tf.FixedLenFeature([MAX_SEQ_LENGTH], tf.int64),\n",
        "        \"segment_ids\": tf.FixedLenFeature([MAX_SEQ_LENGTH], tf.int64),\n",
        "        \"label_ids\": tf.FixedLenFeature([], tf.int64),\n",
        "      }\n",
        "    serialized_tf_example = tf.placeholder(dtype=tf.string,\n",
        "                                           shape=[None],\n",
        "                                           name='input_example_tensor')\n",
        "    receiver_tensors = {'examples': serialized_tf_example}\n",
        "    features = tf.parse_example(serialized_tf_example, feature_spec)\n",
        "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)\n",
        "\n",
        "EXPORT_DIR = './Exported models/'+modelname\n",
        "estimator._export_to_tpu = False  # this is important\n",
        "path = estimator.export_savedmodel(EXPORT_DIR, serving_input_fn)\n",
        "print(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T_uo6Dx541fv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check if we can load it correctly:"
      ]
    },
    {
      "metadata": {
        "id": "EhzKyl5U46IB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "subdirs = [x for x in Path(EXPORT_DIR).iterdir()\n",
        "           if x.is_dir() and 'temp' not in str(x)]\n",
        "latest = str(sorted(subdirs)[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_sn23K0a5Qwt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib import predictor\n",
        "\n",
        "predict_fn = predictor.from_saved_model(latest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OsrbTD2EJTVl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getPrediction(in_sentences):\n",
        "  labels = [\"Not an error\", \"Is an error\"]\n",
        "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x[0], text_b = x[1], label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
        "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  # predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
        "  predictions = predict_fn(input_features)\n",
        "  return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4CbCTzuk3SL9",
        "colab_type": "code",
        "outputId": "a1a9ae96-16cd-4d96-ede0-dedeadcc0bc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "import itertools\n",
        "\n",
        "nltk.download('perluniprops')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Package perluniprops is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "iPJwPeOa80Qc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "tknzr = TweetTokenizer()\n",
        "\n",
        "from nltk.tokenize.moses import MosesDetokenizer\n",
        "detokenizer = MosesDetokenizer()\n",
        "\n",
        "def annotate(text):\n",
        "  current_time = datetime.now()\n",
        "  raw = text\n",
        "  raw = re.sub(r'\\s', ' ', raw)\n",
        "  raw = re.sub(r'( )+', ' ', raw)\n",
        "  sentences = nltk.sent_tokenize(raw)\n",
        "  wordsoup = []\n",
        "  annotation_set = []\n",
        "  checking_ids = []\n",
        "  tokens = []\n",
        "  J = 0\n",
        "  for sentence in sentences:\n",
        "    wordsoup.append(tknzr.tokenize(sentence))\n",
        "  for i in range(len(wordsoup)):\n",
        "    tokenized_sentence = wordsoup[i]\n",
        "    for j in range(len(tokenized_sentence)):\n",
        "      token = tokenized_sentence[j]\n",
        "      if not re.search(r'[a-zA-Z]', token):\n",
        "        tokens.append([token, 0])\n",
        "      else:\n",
        "        tokens.append([token, None])\n",
        "        substring = token\n",
        "        si = i-2\n",
        "        if si < 0:\n",
        "          si = 0\n",
        "        detokenizing_string = wordsoup[si:i] + [tokenized_sentence[:j] + ['[MASK]'] + tokenized_sentence[j+1:]] + wordsoup[i+1:i+3]\n",
        "        detokenizing_string = [item for sublist in detokenizing_string for item in sublist]\n",
        "        entry = detokenizer.detokenize(detokenizing_string, return_str=True)\n",
        "        annotation_set.append([entry, substring])\n",
        "        checking_ids.append(J)\n",
        "      J += 1\n",
        "  predictions = getPrediction(annotation_set)\n",
        "  for p in range(len(predictions)):\n",
        "    if predictions[p][-1] == 'Is an error':\n",
        "      tokens[checking_ids[p]][1] = 1\n",
        "    else:\n",
        "      tokens[checking_ids[p]][1] = 0\n",
        "  print('\\n')\n",
        "  print(\"Annotation took time \", datetime.now() - current_time)\n",
        "  return tokens\n",
        "\n",
        "def print_annotated_webpage(tokens, title):\n",
        "  out = '<html>\\n<head>\\n<title>'+title+'</title>\\n<meta charset=\"utf-8\">\\n<style type=\"text/css\">\\n.blue {\\n\\tbackground: #a8d1ff;\\n\\tdisplay: inline-block;\\n}\\n</style>\\n</head>\\n<body>'\n",
        "  outsoup = []\n",
        "  for token in tokens:\n",
        "    if token[1] == 1:\n",
        "      token[0] = '<div class=\"blue\">'+token[0]+'</div>'\n",
        "    outsoup.append(token[0])\n",
        "  bodystring = detokenizer.detokenize(outsoup, return_str=True)\n",
        "  out += bodystring\n",
        "  out += '</body>\\n</html>'\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lrnyWIYaCNng",
        "colab_type": "code",
        "outputId": "2a4f3799-82a7-492f-9320-576077dde269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4085
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "curname = \"wsites_\" + Model_name + \".json\"\n",
        "\n",
        "test_texts = {'DTi_50_2': \"\"\"It is widely known that music labels and film makers lose a great deal of money every year from illegal copying and free internet sharing. Some people say that people who do that should be punished, some think that such men are the new «Robin Hoods». Let us take a look at this problem.\n",
        "On the one hand, illegal copying is prohibited in almost all civilized countries and there is a reason for that. Music, books and films are considered as an intellectual property and it is quite uderstandable because artists are getting paid for composing, painting and film making only if their products sell, and if they do not have enough money for their living and creating they will just get another job, and this is why the law of intellectual property exists. It helps artists to get money they deserve and to have enough funds to make a quality product.\n",
        "On the other hand, nowadays it is not so simple as it may look like at first. Musicians do not often need labels to record their masterpieces anymore because personal computers went so far that now you can record some high-quality sound right in your living room so you do not need to rent a studio for that. As for film makers, they get millions just by dressing the main character in a big logo T-shirt of some reach corporation. In fact, money, that a film company is paid for commercial, can sometimes fully cover the film making expences. \n",
        "To conclude, I would like to say that we should obey the law of intellectual property. If we want to live in a respectful society, but sometimes, I think we should also ask ourselves what we are paying for.\"\"\",\n",
        "'VSa_105_1': \"\"\"The graph provides information about development of the book sales system in 4 different countries (USA, Germany, China, UK) in 2014 and predicts future perspectives of this industry in 2018.\n",
        "Generally speaking, it is observed a great increase of eBook on the market in the USA in 2018, which will surpass printed sources. By contrast, in other countries, except the UK, printed literature will remain constant position.\n",
        "Despite the fact that print dominated on the book market of the USA in 2014 and exceeded eBook by a half (10,5 to 5,5 respectively), in 2018 it is forecasted that benefit of print literature will shrink on 3 billion US dollars. At the same time the income of eBook will grow on 3 billion US dollars and will be the most selling source of literature (8,5 billion $ of Ebook as against 7,5 billion $ of print).\n",
        "In other countries the book market is not so developed as it in the USA. However, it is forecasted that in 2018 the ebook sales will slightly overtake printed book sales (2,3 to 2 respectively).\n",
        "In Germany and China printed books will be the most popular kind of literature (6 to 4,2 respectively), especially in Germany print indicators remain stable.\n",
        "But it also be a small growth in sales of Ebooks in these countries (from 1 to 1,5 in German and from 0,5 to 1 in China).\"\"\",\n",
        "'NMya_90_1': \"\"\"On the first graph we can see information about maximal and minimal average temperatures in Yakutsk. Graphs for both, the minimum and maximum have a parabolic appearance: they both have a steady increase until the hottest month of the year (july) and after that they both have as constant decrease down to december. Analazing this whole graph, you can point out several things. First of all, the difference of the highest and lowest temperatures between the coldest month and the hottest month is sixty degrees and fifty degrees respectively. The biggest difference between maximum and minimum temperatures is seen on march and it is about seventeen degrees. According to this graph, july is always the hottest month and january is the coldest.\n",
        "\n",
        "On the second graph we can see similar temperature comparsions for Rio de Janeiro. Two lines represent minimum and maximum average temperatures for every month of the year. According to this graph, temperatures in Rio don’t change much throughout the year. the maximal difference of minimum and maximum temperature is on january, july and august and is approximately only seven degrees. For this city the coldest months are june and july, and the hottest are january and february.\n",
        "\n",
        "Comparing the two graphs we notice this: average year temperature in rio is almost constant, comparing to Yakutsk and is never less then 18 °C, and the coldest and the hottest months in Rio are the hottest and the coldest in Yakutsk.\n",
        "\"\"\",\n",
        "'NChe_16_2': \"\"\"In reacent time a lot of people claims that modern technology is a curse that leads to a health problems. It is no use to argue with this statement.\n",
        "For begining,  many doctors already said, that such things like computers can caus a lot of prolems with heath. So, one of the most famous illness is damaged eyes. Then kids or adults spend a load of time next to monitor they starting to lose eyes sharphes. What is more, some scientiest claiws that some deuices cau lead euen cancer. There is no uniqe poiut betwine doctors, any way there is such kind of danger.\n",
        "As for my, I find this problems not so unreducable. In general, all health desiases caused by modern techuologies were caused by ouer-use of this technologies and useing it in anpropriate way. So, if people start to control time that they spend with there deuices it will help to recduce a lot of problems with eyes. As a next step, we should understand that lightning aroun us is also very important. That means, that modern technologies haue some bad influens on people, but we can also dicrease that bad effect.\n",
        "To sum up, wiede use of modern technology shown us that there are not only benefits in deuelopmeut of deuices, but also the great danger. But corect use of it can reduce to the minimum all harmful effects\"\"\",\n",
        "'ESha_3_2': \"\"\"Nowadays it is becoming cosier to express yourself by different ways. Some people do it by using words, some by using pictures of films. But is it clear to allow artist to do and to act how they want? \n",
        "\n",
        "\n",
        "There are so many ways to express your thoghts and feelings. People from ancient times show their ideas and thoughts by paintings and music. A lot of paintings of famous authors are held now in different galleries and big amount of people see them every day. But in long time ago just really talanted people become famous and well known artists.\n",
        "\n",
        "\n",
        "Now situation is different. Every person can become an artist. Sometimes, people don't think how their ideas and works would influence other people's minds. Too many untalanted and unproffesional people create music, movies and paintings. It is really hard for a good artist to show himself in such amount of untalanted people.\n",
        "\n",
        "\n",
        "In my opinion, government should allowed to express ideas and thoughts stronly really good artists. I their ideas are clear and they have something to show and tell people, they should do it. But if artist's works don't have any idea or logic or it can't bring anything good to public, there is nothing to show.\n",
        "\n",
        "\n",
        "Every person have a chance to show itself by any way he choose. But at first, we should think, if he really wants it and if she really have something to say and show to bublicity. Only really good works should be shown to people, because it can influence them and their minds a lot.\n",
        "\"\"\"}\n",
        "\n",
        "outie = [print_annotated_webpage(annotate(test_texts[tt]), tt) for tt in test_texts]\n",
        "with open(curname, 'w', encoding=\"utf-8\") as w:\n",
        "  json.dump(outie, w)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 290\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] [MASK] is widely known that music labels and film makers lose a great deal of money every year from illegal copying and free internet sharing . some people say that people who do that should be punished , some think that such men are the new « robin hood ##s » . let us take a look at this problem . [SEP] it [SEP]\n",
            "INFO:tensorflow:input_ids: 101 103 2003 4235 2124 2008 2189 10873 1998 2143 11153 4558 1037 2307 3066 1997 2769 2296 2095 2013 6206 24731 1998 2489 4274 6631 1012 2070 2111 2360 2008 2111 2040 2079 2008 2323 2022 14248 1010 2070 2228 2008 2107 2273 2024 1996 2047 1077 5863 7415 2015 1090 1012 2292 2149 2202 1037 2298 2012 2023 3291 1012 102 2009 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] it [MASK] widely known that music labels and film makers lose a great deal of money every year from illegal copying and free internet sharing . some people say that people who do that should be punished , some think that such men are the new « robin hood ##s » . let us take a look at this problem . [SEP] is [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2009 103 4235 2124 2008 2189 10873 1998 2143 11153 4558 1037 2307 3066 1997 2769 2296 2095 2013 6206 24731 1998 2489 4274 6631 1012 2070 2111 2360 2008 2111 2040 2079 2008 2323 2022 14248 1010 2070 2228 2008 2107 2273 2024 1996 2047 1077 5863 7415 2015 1090 1012 2292 2149 2202 1037 2298 2012 2023 3291 1012 102 2003 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] it is [MASK] known that music labels and film makers lose a great deal of money every year from illegal copying and free internet sharing . some people say that people who do that should be punished , some think that such men are the new « robin hood ##s » . let us take a look at this problem . [SEP] widely [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2009 2003 103 2124 2008 2189 10873 1998 2143 11153 4558 1037 2307 3066 1997 2769 2296 2095 2013 6206 24731 1998 2489 4274 6631 1012 2070 2111 2360 2008 2111 2040 2079 2008 2323 2022 14248 1010 2070 2228 2008 2107 2273 2024 1996 2047 1077 5863 7415 2015 1090 1012 2292 2149 2202 1037 2298 2012 2023 3291 1012 102 4235 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] it is widely [MASK] that music labels and film makers lose a great deal of money every year from illegal copying and free internet sharing . some people say that people who do that should be punished , some think that such men are the new « robin hood ##s » . let us take a look at this problem . [SEP] known [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2009 2003 4235 103 2008 2189 10873 1998 2143 11153 4558 1037 2307 3066 1997 2769 2296 2095 2013 6206 24731 1998 2489 4274 6631 1012 2070 2111 2360 2008 2111 2040 2079 2008 2323 2022 14248 1010 2070 2228 2008 2107 2273 2024 1996 2047 1077 5863 7415 2015 1090 1012 2292 2149 2202 1037 2298 2012 2023 3291 1012 102 2124 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] it is widely known [MASK] music labels and film makers lose a great deal of money every year from illegal copying and free internet sharing . some people say that people who do that should be punished , some think that such men are the new « robin hood ##s » . let us take a look at this problem . [SEP] that [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2009 2003 4235 2124 103 2189 10873 1998 2143 11153 4558 1037 2307 3066 1997 2769 2296 2095 2013 6206 24731 1998 2489 4274 6631 1012 2070 2111 2360 2008 2111 2040 2079 2008 2323 2022 14248 1010 2070 2228 2008 2107 2273 2024 1996 2047 1077 5863 7415 2015 1090 1012 2292 2149 2202 1037 2298 2012 2023 3291 1012 102 2008 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from OUTPUT_DIR_NAME/model.ckpt-1874\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "\n",
            "Annotation took time  0:00:13.455726\n",
            "INFO:tensorflow:Writing example 0 of 209\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] [MASK] graph provides information about development of the book sales system in 4 different countries ( usa , germany , china , uk ) in 2014 and predict ##s future perspectives of this industry in 2018 . generally speaking , it is observed a great increase of ebook on the market in the usa in 2018 , which will sur ##pass printed sources . by contrast , in other countries , except the uk , printed literature will remain constant position . [SEP] the [SEP]\n",
            "INFO:tensorflow:input_ids: 101 103 10629 3640 2592 2055 2458 1997 1996 2338 4341 2291 1999 1018 2367 3032 1006 3915 1010 2762 1010 2859 1010 2866 1007 1999 2297 1998 16014 2015 2925 15251 1997 2023 3068 1999 2760 1012 3227 4092 1010 2009 2003 5159 1037 2307 3623 1997 26885 2006 1996 3006 1999 1996 3915 1999 2760 1010 2029 2097 7505 15194 6267 4216 1012 2011 5688 1010 1999 2060 3032 1010 3272 1996 2866 1010 6267 3906 2097 3961 5377 2597 1012 102 1996 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] the [MASK] provides information about development of the book sales system in 4 different countries ( usa , germany , china , uk ) in 2014 and predict ##s future perspectives of this industry in 2018 . generally speaking , it is observed a great increase of ebook on the market in the usa in 2018 , which will sur ##pass printed sources . by contrast , in other countries , except the uk , printed literature will remain constant position . [SEP] graph [SEP]\n",
            "INFO:tensorflow:input_ids: 101 1996 103 3640 2592 2055 2458 1997 1996 2338 4341 2291 1999 1018 2367 3032 1006 3915 1010 2762 1010 2859 1010 2866 1007 1999 2297 1998 16014 2015 2925 15251 1997 2023 3068 1999 2760 1012 3227 4092 1010 2009 2003 5159 1037 2307 3623 1997 26885 2006 1996 3006 1999 1996 3915 1999 2760 1010 2029 2097 7505 15194 6267 4216 1012 2011 5688 1010 1999 2060 3032 1010 3272 1996 2866 1010 6267 3906 2097 3961 5377 2597 1012 102 10629 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] the graph [MASK] information about development of the book sales system in 4 different countries ( usa , germany , china , uk ) in 2014 and predict ##s future perspectives of this industry in 2018 . generally speaking , it is observed a great increase of ebook on the market in the usa in 2018 , which will sur ##pass printed sources . by contrast , in other countries , except the uk , printed literature will remain constant position . [SEP] provides [SEP]\n",
            "INFO:tensorflow:input_ids: 101 1996 10629 103 2592 2055 2458 1997 1996 2338 4341 2291 1999 1018 2367 3032 1006 3915 1010 2762 1010 2859 1010 2866 1007 1999 2297 1998 16014 2015 2925 15251 1997 2023 3068 1999 2760 1012 3227 4092 1010 2009 2003 5159 1037 2307 3623 1997 26885 2006 1996 3006 1999 1996 3915 1999 2760 1010 2029 2097 7505 15194 6267 4216 1012 2011 5688 1010 1999 2060 3032 1010 3272 1996 2866 1010 6267 3906 2097 3961 5377 2597 1012 102 3640 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] the graph provides [MASK] about development of the book sales system in 4 different countries ( usa , germany , china , uk ) in 2014 and predict ##s future perspectives of this industry in 2018 . generally speaking , it is observed a great increase of ebook on the market in the usa in 2018 , which will sur ##pass printed sources . by contrast , in other countries , except the uk , printed literature will remain constant position . [SEP] information [SEP]\n",
            "INFO:tensorflow:input_ids: 101 1996 10629 3640 103 2055 2458 1997 1996 2338 4341 2291 1999 1018 2367 3032 1006 3915 1010 2762 1010 2859 1010 2866 1007 1999 2297 1998 16014 2015 2925 15251 1997 2023 3068 1999 2760 1012 3227 4092 1010 2009 2003 5159 1037 2307 3623 1997 26885 2006 1996 3006 1999 1996 3915 1999 2760 1010 2029 2097 7505 15194 6267 4216 1012 2011 5688 1010 1999 2060 3032 1010 3272 1996 2866 1010 6267 3906 2097 3961 5377 2597 1012 102 2592 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] the graph provides information [MASK] development of the book sales system in 4 different countries ( usa , germany , china , uk ) in 2014 and predict ##s future perspectives of this industry in 2018 . generally speaking , it is observed a great increase of ebook on the market in the usa in 2018 , which will sur ##pass printed sources . by contrast , in other countries , except the uk , printed literature will remain constant position . [SEP] about [SEP]\n",
            "INFO:tensorflow:input_ids: 101 1996 10629 3640 2592 103 2458 1997 1996 2338 4341 2291 1999 1018 2367 3032 1006 3915 1010 2762 1010 2859 1010 2866 1007 1999 2297 1998 16014 2015 2925 15251 1997 2023 3068 1999 2760 1012 3227 4092 1010 2009 2003 5159 1037 2307 3623 1997 26885 2006 1996 3006 1999 1996 3915 1999 2760 1010 2029 2097 7505 15194 6267 4216 1012 2011 5688 1010 1999 2060 3032 1010 3272 1996 2866 1010 6267 3906 2097 3961 5377 2597 1012 102 2055 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from OUTPUT_DIR_NAME/model.ckpt-1874\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "\n",
            "Annotation took time  0:00:11.745770\n",
            "INFO:tensorflow:Writing example 0 of 242\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] [MASK] the first graph we can see information about maximal and minimal average temperatures in ya ##ku ##tsk . graphs for both , the minimum and maximum have a para ##bolic appearance : they both have a steady increase until the hottest month of the year ( july ) and after that they both have as constant decrease down to december . anal ##azi ##ng this whole graph , you can point out several things . [SEP] on [SEP]\n",
            "INFO:tensorflow:input_ids: 101 103 1996 2034 10629 2057 2064 2156 2592 2055 29160 1998 10124 2779 7715 1999 8038 5283 29064 1012 19287 2005 2119 1010 1996 6263 1998 4555 2031 1037 11498 18647 3311 1024 2027 2119 2031 1037 6706 3623 2127 1996 20930 3204 1997 1996 2095 1006 2251 1007 1998 2044 2008 2027 2119 2031 2004 5377 9885 2091 2000 2285 1012 20302 16103 3070 2023 2878 10629 1010 2017 2064 2391 2041 2195 2477 1012 102 2006 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] on [MASK] first graph we can see information about maximal and minimal average temperatures in ya ##ku ##tsk . graphs for both , the minimum and maximum have a para ##bolic appearance : they both have a steady increase until the hottest month of the year ( july ) and after that they both have as constant decrease down to december . anal ##azi ##ng this whole graph , you can point out several things . [SEP] the [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2006 103 2034 10629 2057 2064 2156 2592 2055 29160 1998 10124 2779 7715 1999 8038 5283 29064 1012 19287 2005 2119 1010 1996 6263 1998 4555 2031 1037 11498 18647 3311 1024 2027 2119 2031 1037 6706 3623 2127 1996 20930 3204 1997 1996 2095 1006 2251 1007 1998 2044 2008 2027 2119 2031 2004 5377 9885 2091 2000 2285 1012 20302 16103 3070 2023 2878 10629 1010 2017 2064 2391 2041 2195 2477 1012 102 1996 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] on the [MASK] graph we can see information about maximal and minimal average temperatures in ya ##ku ##tsk . graphs for both , the minimum and maximum have a para ##bolic appearance : they both have a steady increase until the hottest month of the year ( july ) and after that they both have as constant decrease down to december . anal ##azi ##ng this whole graph , you can point out several things . [SEP] first [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2006 1996 103 10629 2057 2064 2156 2592 2055 29160 1998 10124 2779 7715 1999 8038 5283 29064 1012 19287 2005 2119 1010 1996 6263 1998 4555 2031 1037 11498 18647 3311 1024 2027 2119 2031 1037 6706 3623 2127 1996 20930 3204 1997 1996 2095 1006 2251 1007 1998 2044 2008 2027 2119 2031 2004 5377 9885 2091 2000 2285 1012 20302 16103 3070 2023 2878 10629 1010 2017 2064 2391 2041 2195 2477 1012 102 2034 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] on the first [MASK] we can see information about maximal and minimal average temperatures in ya ##ku ##tsk . graphs for both , the minimum and maximum have a para ##bolic appearance : they both have a steady increase until the hottest month of the year ( july ) and after that they both have as constant decrease down to december . anal ##azi ##ng this whole graph , you can point out several things . [SEP] graph [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2006 1996 2034 103 2057 2064 2156 2592 2055 29160 1998 10124 2779 7715 1999 8038 5283 29064 1012 19287 2005 2119 1010 1996 6263 1998 4555 2031 1037 11498 18647 3311 1024 2027 2119 2031 1037 6706 3623 2127 1996 20930 3204 1997 1996 2095 1006 2251 1007 1998 2044 2008 2027 2119 2031 2004 5377 9885 2091 2000 2285 1012 20302 16103 3070 2023 2878 10629 1010 2017 2064 2391 2041 2195 2477 1012 102 10629 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] on the first graph [MASK] can see information about maximal and minimal average temperatures in ya ##ku ##tsk . graphs for both , the minimum and maximum have a para ##bolic appearance : they both have a steady increase until the hottest month of the year ( july ) and after that they both have as constant decrease down to december . anal ##azi ##ng this whole graph , you can point out several things . [SEP] we [SEP]\n",
            "INFO:tensorflow:input_ids: 101 2006 1996 2034 10629 103 2064 2156 2592 2055 29160 1998 10124 2779 7715 1999 8038 5283 29064 1012 19287 2005 2119 1010 1996 6263 1998 4555 2031 1037 11498 18647 3311 1024 2027 2119 2031 1037 6706 3623 2127 1996 20930 3204 1997 1996 2095 1006 2251 1007 1998 2044 2008 2027 2119 2031 2004 5377 9885 2091 2000 2285 1012 20302 16103 3070 2023 2878 10629 1010 2017 2064 2391 2041 2195 2477 1012 102 2057 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from OUTPUT_DIR_NAME/model.ckpt-1874\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "\n",
            "Annotation took time  0:00:12.568108\n",
            "INFO:tensorflow:Writing example 0 of 232\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] [MASK] re ##ace ##nt time a lot of people claims that modern technology is a curse that leads to a health problems . it is no use to argue with this statement . for begin ##ing , many doctors already said , that such things like computers can ca ##us a lot of pro ##lem ##s with heath . [SEP] in [SEP]\n",
            "INFO:tensorflow:input_ids: 101 103 2128 10732 3372 2051 1037 2843 1997 2111 4447 2008 2715 2974 2003 1037 8364 2008 5260 2000 1037 2740 3471 1012 2009 2003 2053 2224 2000 7475 2007 2023 4861 1012 2005 4088 2075 1010 2116 7435 2525 2056 1010 2008 2107 2477 2066 7588 2064 6187 2271 1037 2843 1997 4013 16930 2015 2007 9895 1012 102 1999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] in [MASK] time a lot of people claims that modern technology is a curse that leads to a health problems . it is no use to argue with this statement . for begin ##ing , many doctors already said , that such things like computers can ca ##us a lot of pro ##lem ##s with heath . [SEP] re ##ace ##nt [SEP]\n",
            "INFO:tensorflow:input_ids: 101 1999 103 2051 1037 2843 1997 2111 4447 2008 2715 2974 2003 1037 8364 2008 5260 2000 1037 2740 3471 1012 2009 2003 2053 2224 2000 7475 2007 2023 4861 1012 2005 4088 2075 1010 2116 7435 2525 2056 1010 2008 2107 2477 2066 7588 2064 6187 2271 1037 2843 1997 4013 16930 2015 2007 9895 1012 102 2128 10732 3372 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] in re ##ace ##nt [MASK] a lot of people claims that modern technology is a curse that leads to a health problems . it is no use to argue with this statement . for begin ##ing , many doctors already said , that such things like computers can ca ##us a lot of pro ##lem ##s with heath . [SEP] time [SEP]\n",
            "INFO:tensorflow:input_ids: 101 1999 2128 10732 3372 103 1037 2843 1997 2111 4447 2008 2715 2974 2003 1037 8364 2008 5260 2000 1037 2740 3471 1012 2009 2003 2053 2224 2000 7475 2007 2023 4861 1012 2005 4088 2075 1010 2116 7435 2525 2056 1010 2008 2107 2477 2066 7588 2064 6187 2271 1037 2843 1997 4013 16930 2015 2007 9895 1012 102 2051 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] in re ##ace ##nt time [MASK] lot of people claims that modern technology is a curse that leads to a health problems . it is no use to argue with this statement . for begin ##ing , many doctors already said , that such things like computers can ca ##us a lot of pro ##lem ##s with heath . [SEP] a [SEP]\n",
            "INFO:tensorflow:input_ids: 101 1999 2128 10732 3372 2051 103 2843 1997 2111 4447 2008 2715 2974 2003 1037 8364 2008 5260 2000 1037 2740 3471 1012 2009 2003 2053 2224 2000 7475 2007 2023 4861 1012 2005 4088 2075 1010 2116 7435 2525 2056 1010 2008 2107 2477 2066 7588 2064 6187 2271 1037 2843 1997 4013 16930 2015 2007 9895 1012 102 1037 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] in re ##ace ##nt time a [MASK] of people claims that modern technology is a curse that leads to a health problems . it is no use to argue with this statement . for begin ##ing , many doctors already said , that such things like computers can ca ##us a lot of pro ##lem ##s with heath . [SEP] lot [SEP]\n",
            "INFO:tensorflow:input_ids: 101 1999 2128 10732 3372 2051 1037 103 1997 2111 4447 2008 2715 2974 2003 1037 8364 2008 5260 2000 1037 2740 3471 1012 2009 2003 2053 2224 2000 7475 2007 2023 4861 1012 2005 4088 2075 1010 2116 7435 2525 2056 1010 2008 2107 2477 2066 7588 2064 6187 2271 1037 2843 1997 4013 16930 2015 2007 9895 1012 102 2843 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from OUTPUT_DIR_NAME/model.ckpt-1874\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "\n",
            "Annotation took time  0:00:12.039969\n",
            "INFO:tensorflow:Writing example 0 of 263\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] [MASK] it is becoming co ##sier to express yourself by different ways . some people do it by using words , some by using pictures of films . but is it clear to allow artist to do and to act how they want ? [SEP] nowadays [SEP]\n",
            "INFO:tensorflow:input_ids: 101 103 2009 2003 3352 2522 20236 2000 4671 4426 2011 2367 3971 1012 2070 2111 2079 2009 2011 2478 2616 1010 2070 2011 2478 4620 1997 3152 1012 2021 2003 2009 3154 2000 3499 3063 2000 2079 1998 2000 2552 2129 2027 2215 1029 102 13367 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] nowadays [MASK] is becoming co ##sier to express yourself by different ways . some people do it by using words , some by using pictures of films . but is it clear to allow artist to do and to act how they want ? [SEP] it [SEP]\n",
            "INFO:tensorflow:input_ids: 101 13367 103 2003 3352 2522 20236 2000 4671 4426 2011 2367 3971 1012 2070 2111 2079 2009 2011 2478 2616 1010 2070 2011 2478 4620 1997 3152 1012 2021 2003 2009 3154 2000 3499 3063 2000 2079 1998 2000 2552 2129 2027 2215 1029 102 2009 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] nowadays it [MASK] becoming co ##sier to express yourself by different ways . some people do it by using words , some by using pictures of films . but is it clear to allow artist to do and to act how they want ? [SEP] is [SEP]\n",
            "INFO:tensorflow:input_ids: 101 13367 2009 103 3352 2522 20236 2000 4671 4426 2011 2367 3971 1012 2070 2111 2079 2009 2011 2478 2616 1010 2070 2011 2478 4620 1997 3152 1012 2021 2003 2009 3154 2000 3499 3063 2000 2079 1998 2000 2552 2129 2027 2215 1029 102 2003 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] nowadays it is [MASK] co ##sier to express yourself by different ways . some people do it by using words , some by using pictures of films . but is it clear to allow artist to do and to act how they want ? [SEP] becoming [SEP]\n",
            "INFO:tensorflow:input_ids: 101 13367 2009 2003 103 2522 20236 2000 4671 4426 2011 2367 3971 1012 2070 2111 2079 2009 2011 2478 2616 1010 2070 2011 2478 4620 1997 3152 1012 2021 2003 2009 3154 2000 3499 3063 2000 2079 1998 2000 2552 2129 2027 2215 1029 102 3352 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: \n",
            "INFO:tensorflow:tokens: [CLS] nowadays it is becoming [MASK] to express yourself by different ways . some people do it by using words , some by using pictures of films . but is it clear to allow artist to do and to act how they want ? [SEP] co ##sier [SEP]\n",
            "INFO:tensorflow:input_ids: 101 13367 2009 2003 3352 103 2000 4671 4426 2011 2367 3971 1012 2070 2111 2079 2009 2011 2478 2616 1010 2070 2011 2478 4620 1997 3152 1012 2021 2003 2009 3154 2000 3499 3063 2000 2079 1998 2000 2552 2129 2027 2215 1029 102 2522 20236 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from OUTPUT_DIR_NAME/model.ckpt-1874\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "\n",
            "Annotation took time  0:00:12.158832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3w4nJBGMOuz5",
        "colab_type": "code",
        "outputId": "e865f978-f267-4b71-aaa4-029572d260e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Create & upload a file.\n",
        "uploaded = drive.CreateFile({'title': curname})\n",
        "uploaded.SetContentFile('./'+curname)\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 16_pmUKOHS5lKXM2o-1QyVcPQohalCRZd\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zk7zf0Qu3Bp8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preparing existing model for REALEC production"
      ]
    }
  ]
}